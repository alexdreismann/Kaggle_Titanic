{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for the 'Titanic' challenge of Kaggle\n",
    "\n",
    "Following the instructions given at: https://www.dataquest.io/mission/74/getting-started-with-kaggle\n",
    "\n",
    "### Import stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data set and get a feel for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex  Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male   22      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
      "2                             Heikkinen, Miss. Laina  female   26      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
      "4                           Allen, Mr. William Henry    male   35      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('train.csv')\n",
    "print (titanic_df.head())\n",
    "print (titanic_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Cound' gives the number of non-missing (null, NA, NaN) values. The 'Age' column apparently has some empty spaces. Since we do not want to delete the corresponding rows (more data makes better training), nor the whole column ('Age' is possibly important for the analysis), the data needs to be cleaned up. \n",
    "\n",
    "A common way for doing this is by writing the median of the column into the empty places. Use the '.fillna()' method to replace missing values with the median, the latter being computed with '.median()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "titanic_df[\"Age\"].fillna(titanic_df[\"Age\"].median(),inplace=True)\n",
    "print (titanic_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'.describe()' does not evaluate all of the columns, since some of them are not numeric. To use the non-numeric columns for the algorithms used below, they should be transformed to some numeric value. We will do this for the 'Sex' column. 'Embarked', 'Cabin' and 'Name' are possibly hard to evaluate without further specialised knowledge, so we will igonre them for the moment.\n",
    "\n",
    "Replace all 'male' entries with '0' and all 'female' entries with '1'. To find the indices of the 'male' entries, use: 'titanic_df.loc[titanic_df[\"Sex\"] == \"male\", \"Sex\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_df.loc[titanic_df[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_df.loc[titanic_df[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next replace the values of the 'Embarked' column with numbers. The unique values of the 'Embarked' column are 'S', 'C' and 'Q', which will be replaced with 0, 1 and 2, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print (titanic_df['Embarked'].unique())\n",
    "titanic_df['Embarked'].fillna('S',inplace=True)\n",
    "titanic_df.loc[titanic_df['Embarked'] == 'S', 'Embarked'] = 0\n",
    "titanic_df.loc[titanic_df['Embarked'] == 'C', 'Embarked'] = 1\n",
    "titanic_df.loc[titanic_df['Embarked'] == 'Q', 'Embarked'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression and cross validation\n",
    "\n",
    "**Linear regression** essentially means - if I understand correctly - that predictions are made based on a linear function of the input parameters. For instance, the 'survived' value could be predicted as $y_i = \\alpha \\cdot x_i + \\beta$. \n",
    "\n",
    "**Cross validation** means that the algorithm is trained on one part of the data set (i.e. a linear fit is performed), and another part is used to test how good the prediction is. This is done to avoid 'overfitting', which could arise from accidentally fitting to some particular properties of the training data set. \n",
    "\n",
    "Here we use the 'scikit-learn' library to partition the data set for cross fitting and make predicitons using linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(titanic_df.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic_df[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic_df[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic_df[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll first need to define an error metric, so we can figure out how accurate our model is. From the Kaggle competition description, the error metric is percentage of correct predictions. The metric will basically involve finding the number of values in 'predictions' that are the exact same as their counterparts in 'titanic[\"Survived\"]', and then dividing by the total number of passengers. Before we can do this, we need to combine the 3 sets of predictions into one column (done above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "\n",
    "accuracy = np.sum(np.array(titanic_df['Survived']) == predictions)/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "Squeeze prediciton values between '0' and '1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import cross_validation\n",
    "\n",
    "# Initialize our algorithm\n",
    "#alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "#scores = cross_validation.cross_val_score(alg, titanic_df[predictors], titanic_df[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "#print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use algorithm on full data set\n",
    "\n",
    "First clean up test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv(\"test.csv\")\n",
    "titanic_test['Age'].fillna(titanic_df['Age'].median(),inplace=True)\n",
    "titanic_test.loc[titanic_test['Sex'] == 'male', 'Sex'] = 0\n",
    "titanic_test.loc[titanic_test['Sex'] == 'female', 'Sex'] = 1\n",
    "titanic_test['Embarked'].fillna('S',inplace=True)\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'S', 'Embarked'] = 0\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'C', 'Embarked'] = 1\n",
    "titanic_test.loc[titanic_test['Embarked'] == 'Q', 'Embarked'] = 2\n",
    "titanic_test['Fare'].fillna(titanic_test['Fare'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
